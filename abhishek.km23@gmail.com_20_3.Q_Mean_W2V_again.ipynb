{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "from collections import Counter\n",
    "from collections import Counter, defaultdict\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import joblib\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "df_train = df[:70000]\n",
    "df_test = df[70000:100000]\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df_train['question1'] = df_train['question1'].apply(lambda x: str(x))\n",
    "df_train['question2'] = df_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "df_test['question1'] = df_test['question1'].apply(lambda x: str(x))\n",
    "df_test['question2'] = df_test['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 14:38:05.153887\n",
      "Time taken to run this cell 0:00:11.290700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "# merge texts\n",
    "questions_train = list(df_train['question1']) + list(df_train['question2']) \n",
    "questions_test = list(df_test['question1']) + list(df_test['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions_train)\n",
    "tfidf.transform(questions_test)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(df_train['question1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFS6m8z5dMUz",
    "outputId": "3c4fb6fd-7f86-4955-8b8f-762b5969ecce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 14:44:37.209707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 70000/70000 [55:24<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell 0:55:27.805032\n"
     ]
    }
   ],
   "source": [
    "# vectorizing train data of question1\n",
    "# last comment worked: https://stackoverflow.com/questions/49964028/spacy-oserror-cant-find-model-en\n",
    "\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(df_train['question1']):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "df_train['q1_feats_m_train'] = list(vecs1)\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62GEF-RbdMVB",
    "outputId": "60a4f5f8-5582-4886-befd-2ab6ed99c753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 15:41:58.087603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 70000/70000 [54:53<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell 0:54:53.656920\n"
     ]
    }
   ],
   "source": [
    "# vectorizing train data of question2\n",
    "\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "vecs2 = []\n",
    "for qu2 in tqdm(df_train['question2']):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc1), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "\n",
    "df_train['q2_feats_m_train'] = list(vecs2)\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 16:36:51.773923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30000/30000 [29:00<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell 0:29:03.005378\n"
     ]
    }
   ],
   "source": [
    "# vectorizing test data of question1\n",
    "\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(df_test['question1']):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "\n",
    "df_test['q1_feats_m_test'] = list(vecs1)\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 17:05:54.822112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30000/30000 [28:58<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell 0:28:59.068028\n"
     ]
    }
   ],
   "source": [
    "# vectorizing test data of question2\n",
    "\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "vecs2 = []\n",
    "for qu2 in tqdm(df_test['question2']):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc1), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "\n",
    "df_test['q2_feats_m_test'] = list(vecs2)\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 17:43:40.710343\n",
      "Time taken to run this cell 0:01:31.432278\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime)\n",
    "\n",
    "ques_1_train_df = pd.DataFrame(df_train['q1_feats_m_train'].tolist())\n",
    "ques_1_test_df = pd.DataFrame(df_train['q2_feats_m_train'].tolist())\n",
    "\n",
    "ques_2_train_df = pd.DataFrame(df_test['q1_feats_m_test'].tolist())\n",
    "ques_2_test_df = pd.DataFrame(df_test['q2_feats_m_test'].tolist())\n",
    "\n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.466664           0.0            1.0           5.0      12.5   \n",
       "2  0.285712           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           2.0      12.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               66                66          54                  54   \n",
       "3               36                36          35                  40   \n",
       "4               67                47          46                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.133332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>0.220779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>68</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>70004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>0.122642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70005</th>\n",
       "      <td>70005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70006</th>\n",
       "      <td>70006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70007</th>\n",
       "      <td>70007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.583328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>83</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70008</th>\n",
       "      <td>70008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70009</th>\n",
       "      <td>70009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.374995</td>\n",
       "      <td>0.749991</td>\n",
       "      <td>0.461535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "70000  70000             1  0.666644  0.666644  0.999967  0.599988  0.833319   \n",
       "70001  70001             0  0.399992  0.249997  0.000000  0.000000  0.153845   \n",
       "70002  70002             0  0.666644  0.499988  0.666644  0.499988  0.571420   \n",
       "70003  70003             0  0.999967  0.749981  0.999975  0.799984  0.999986   \n",
       "70004  70004             0  0.249997  0.249997  0.142855  0.083333  0.187499   \n",
       "70005  70005             0  0.499988  0.499988  0.499975  0.199996  0.499992   \n",
       "70006  70006             1  0.999967  0.749981  0.666644  0.666644  0.833319   \n",
       "70007  70007             1  0.666656  0.571420  0.749981  0.599988  0.699993   \n",
       "70008  70008             0  0.000000  0.000000  0.666644  0.249997  0.249997   \n",
       "70009  70009             0  0.999967  0.999967  0.599988  0.374995  0.749991   \n",
       "\n",
       "        ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "70000  0.624992           0.0            1.0           2.0       7.0   \n",
       "70001  0.133332           0.0            0.0           2.0      14.0   \n",
       "70002  0.571420           0.0            0.0           0.0       7.0   \n",
       "70003  0.777769           0.0            1.0           2.0       8.0   \n",
       "70004  0.124999           0.0            0.0           8.0      20.0   \n",
       "70005  0.333330           0.0            0.0           3.0       7.5   \n",
       "70006  0.714276           0.0            0.0           1.0       6.5   \n",
       "70007  0.583328           1.0            1.0           2.0      11.0   \n",
       "70008  0.142856           0.0            0.0           6.0      11.0   \n",
       "70009  0.461535           1.0            0.0           5.0      10.5   \n",
       "\n",
       "       token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "70000               90                90          68                  76   \n",
       "70001               64                61          41                  42   \n",
       "70002               77                72          70                  68   \n",
       "70003              100                87          87                 100   \n",
       "70004               58                49          52                  53   \n",
       "70005               69                69          60                  76   \n",
       "70006               92                86          86                  91   \n",
       "70007               83                67          75                  70   \n",
       "70008               43                41          37                  43   \n",
       "70009               84                68          70                  75   \n",
       "\n",
       "       longest_substr_ratio  \n",
       "70000              0.411765  \n",
       "70001              0.220779  \n",
       "70002              0.615385  \n",
       "70003              0.972222  \n",
       "70004              0.122642  \n",
       "70005              0.384615  \n",
       "70006              0.857143  \n",
       "70007              0.403509  \n",
       "70008              0.170213  \n",
       "70009              0.682927  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_train = df1[:70000]\n",
    "df1_test = df1[70000:100000]\n",
    "df1_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          4          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          3          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           5           3  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           4           2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>70002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>70003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>70004</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>116</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70005</th>\n",
       "      <td>70005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70006</th>\n",
       "      <td>70006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70007</th>\n",
       "      <td>70007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70008</th>\n",
       "      <td>70008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70009</th>\n",
       "      <td>70009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "70000  70000          1          1     40     33           8           6   \n",
       "70001  70001          1          1     77     76          12          14   \n",
       "70002  70002          1          1     44     38           7           7   \n",
       "70003  70003          1          1     45     35           8           6   \n",
       "70004  70004          4          1    105    116          15          22   \n",
       "70005  70005          1          1     47     38           9           6   \n",
       "70006  70006          2          1     40     34           7           6   \n",
       "70007  70007          1          1     56     69          10          12   \n",
       "70008  70008          1          1     46     75           8          14   \n",
       "70009  70009          1          1     54     40          12           8   \n",
       "\n",
       "       word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "70000          4.0        14.0    0.285714           2           0  \n",
       "70001          1.0        25.0    0.040000           2           0  \n",
       "70002          4.0        14.0    0.285714           2           0  \n",
       "70003          5.0        14.0    0.357143           2           0  \n",
       "70004          3.0        34.0    0.088235           5           3  \n",
       "70005          2.0        15.0    0.133333           2           0  \n",
       "70006          4.0        13.0    0.307692           3           1  \n",
       "70007          7.0        22.0    0.318182           2           0  \n",
       "70008          2.0        22.0    0.090909           2           0  \n",
       "70009          6.0        19.0    0.315789           2           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_train = df2[:70000]\n",
    "df2_test = df2[70000:100000]\n",
    "df2_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>70001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>70002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>70003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>70004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70005</th>\n",
       "      <td>70005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70006</th>\n",
       "      <td>70006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70007</th>\n",
       "      <td>70007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70008</th>\n",
       "      <td>70008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70009</th>\n",
       "      <td>70009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "70000  70000\n",
       "70001  70001\n",
       "70002  70002\n",
       "70003  70003\n",
       "70004  70004\n",
       "70005  70005\n",
       "70006  70006\n",
       "70007  70007\n",
       "70008  70008\n",
       "70009  70009"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train = df3[:70000]\n",
    "df3_test = df3[70000:100000]\n",
    "df3_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_q1_train = pd.DataFrame(ques_1_train_df, index= df3_train.index)\n",
    "df3_q1_test = pd.DataFrame(ques_1_test_df, index= df3_test.index)\n",
    "\n",
    "df3_q2_train = pd.DataFrame(ques_2_train_df, index= df3_train.index)\n",
    "df3_q2_test = pd.DataFrame(ques_2_test_df, index= df3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 17\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v  dataframe : 384\n",
      "Number of features in question2 w2v  dataframe : 384\n",
      "Number of features in final dataframe  : 797\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", ques_1_train_df.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", ques_1_test_df.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+ques_1_train_df.shape[1]+ques_1_test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 17:47:45.417730\n",
      "Time taken to run this cell 0:06:12.196241\n"
     ]
    }
   ],
   "source": [
    "# storing the final features of train data to csv file\n",
    "startTime3 = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime3)\n",
    "\n",
    "if not os.path.isfile('final_features_train_w2v.csv'):\n",
    "    df3_q1_train['id']=df1_train['id']\n",
    "    df3_q2_train['id']=df1_train['id']\n",
    "    df1_train  = df1_train.merge(df2_train, on='id',how='left')\n",
    "    df2_train  = df3_q1_train.merge(df3_q2_train, on='id',how='left')\n",
    "    result  = df1_train.merge(df2_train, on='id',how='left')\n",
    "    result.to_csv('final_features_train_w2v.csv')\n",
    "    \n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>374_y</th>\n",
       "      <th>375_y</th>\n",
       "      <th>376_y</th>\n",
       "      <th>377_y</th>\n",
       "      <th>378_y</th>\n",
       "      <th>379_y</th>\n",
       "      <th>380_y</th>\n",
       "      <th>381_y</th>\n",
       "      <th>382_y</th>\n",
       "      <th>383_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.913172</td>\n",
       "      <td>9.452115</td>\n",
       "      <td>7.700348</td>\n",
       "      <td>-8.207552</td>\n",
       "      <td>7.190231</td>\n",
       "      <td>2.800261</td>\n",
       "      <td>-4.557190</td>\n",
       "      <td>0.837903</td>\n",
       "      <td>8.546584</td>\n",
       "      <td>6.314993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.734211</td>\n",
       "      <td>27.826567</td>\n",
       "      <td>13.032731</td>\n",
       "      <td>-6.930430</td>\n",
       "      <td>3.324043</td>\n",
       "      <td>0.948788</td>\n",
       "      <td>-23.472008</td>\n",
       "      <td>3.298593</td>\n",
       "      <td>28.678169</td>\n",
       "      <td>9.660554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.384814</td>\n",
       "      <td>3.862209</td>\n",
       "      <td>16.417156</td>\n",
       "      <td>-3.425271</td>\n",
       "      <td>-12.746041</td>\n",
       "      <td>-3.043191</td>\n",
       "      <td>-4.743920</td>\n",
       "      <td>12.397037</td>\n",
       "      <td>-0.398171</td>\n",
       "      <td>-13.135662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.311258</td>\n",
       "      <td>12.988016</td>\n",
       "      <td>0.664790</td>\n",
       "      <td>-4.728610</td>\n",
       "      <td>10.399462</td>\n",
       "      <td>5.935001</td>\n",
       "      <td>-4.696811</td>\n",
       "      <td>2.790680</td>\n",
       "      <td>20.241084</td>\n",
       "      <td>-5.227907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.638970</td>\n",
       "      <td>-1.372965</td>\n",
       "      <td>-0.314083</td>\n",
       "      <td>-22.204033</td>\n",
       "      <td>5.011401</td>\n",
       "      <td>15.180408</td>\n",
       "      <td>-10.172982</td>\n",
       "      <td>15.786889</td>\n",
       "      <td>2.275847</td>\n",
       "      <td>2.753095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max  \\\n",
       "0           0   0             0  0.999980  0.833319  0.999983  0.999983   \n",
       "1           1   1             0  0.799984  0.399996  0.749981  0.599988   \n",
       "2           2   2             0  0.399992  0.333328  0.399992  0.249997   \n",
       "3           3   3             0  0.000000  0.000000  0.000000  0.000000   \n",
       "4           4   4             0  0.399992  0.199998  0.999950  0.666644   \n",
       "\n",
       "    ctc_min   ctc_max  last_word_eq    ...          374_y      375_y  \\\n",
       "0  0.916659  0.785709           0.0    ...      -1.913172   9.452115   \n",
       "1  0.699993  0.466664           0.0    ...       8.734211  27.826567   \n",
       "2  0.399996  0.285712           0.0    ...     -18.384814   3.862209   \n",
       "3  0.000000  0.000000           0.0    ...      10.311258  12.988016   \n",
       "4  0.571420  0.307690           0.0    ...      16.638970  -1.372965   \n",
       "\n",
       "       376_y      377_y      378_y      379_y      380_y      381_y  \\\n",
       "0   7.700348  -8.207552   7.190231   2.800261  -4.557190   0.837903   \n",
       "1  13.032731  -6.930430   3.324043   0.948788 -23.472008   3.298593   \n",
       "2  16.417156  -3.425271 -12.746041  -3.043191  -4.743920  12.397037   \n",
       "3   0.664790  -4.728610  10.399462   5.935001  -4.696811   2.790680   \n",
       "4  -0.314083 -22.204033   5.011401  15.180408 -10.172982  15.786889   \n",
       "\n",
       "       382_y      383_y  \n",
       "0   8.546584   6.314993  \n",
       "1  28.678169   9.660554  \n",
       "2  -0.398171 -13.135662  \n",
       "3  20.241084  -5.227907  \n",
       "4   2.275847   2.753095  \n",
       "\n",
       "[5 rows x 797 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_train_w2v = pd.read_csv(\"final_features_train_w2v.csv\")\n",
    "final_features_train_w2v[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 17:58:22.846895\n",
      "Time taken to run this cell 0:01:15.298492\n"
     ]
    }
   ],
   "source": [
    "# storing the final features of test data to csv file\n",
    "startTime = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime)\n",
    "\n",
    "if not os.path.isfile('final_features_test_w2v.csv'):\n",
    "    df3_q1_test['id']=df1_test['id']\n",
    "    df3_q2_test['id']=df1_test['id']\n",
    "    df1_test  = df1_test.merge(df2_test, on='id',how='left')\n",
    "    df2_test  = df3_q1_test.merge(df3_q2_test, on='id',how='left')\n",
    "    result_test  = df1_test.merge(df2_test, on='id',how='left')\n",
    "    result_test.to_csv('final_features_test_w2v.csv')\n",
    "    \n",
    "print(\"Time taken to run this cell {}\".format(datetime.datetime.now() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>374_y</th>\n",
       "      <th>375_y</th>\n",
       "      <th>376_y</th>\n",
       "      <th>377_y</th>\n",
       "      <th>378_y</th>\n",
       "      <th>379_y</th>\n",
       "      <th>380_y</th>\n",
       "      <th>381_y</th>\n",
       "      <th>382_y</th>\n",
       "      <th>383_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.133332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>70004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max  \\\n",
       "0           0  70000             1  0.666644  0.666644  0.999967  0.599988   \n",
       "1           1  70001             0  0.399992  0.249997  0.000000  0.000000   \n",
       "2           2  70002             0  0.666644  0.499988  0.666644  0.499988   \n",
       "3           3  70003             0  0.999967  0.749981  0.999975  0.799984   \n",
       "4           4  70004             0  0.249997  0.249997  0.142855  0.083333   \n",
       "\n",
       "    ctc_min   ctc_max  last_word_eq  ...    374_y  375_y  376_y  377_y  378_y  \\\n",
       "0  0.833319  0.624992           0.0  ...      NaN    NaN    NaN    NaN    NaN   \n",
       "1  0.153845  0.133332           0.0  ...      NaN    NaN    NaN    NaN    NaN   \n",
       "2  0.571420  0.571420           0.0  ...      NaN    NaN    NaN    NaN    NaN   \n",
       "3  0.999986  0.777769           0.0  ...      NaN    NaN    NaN    NaN    NaN   \n",
       "4  0.187499  0.124999           0.0  ...      NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   379_y  380_y  381_y  382_y  383_y  \n",
       "0    NaN    NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 797 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_test_w2v = pd.read_csv(\"final_features_test_w2v.csv\")\n",
    "final_features_test_w2v[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 17:59:46.116073\n",
      "Time taken to run this cell:  0:00:03.002798\n"
     ]
    }
   ],
   "source": [
    "# remove the first row \n",
    "start = datetime.datetime.now()\n",
    "print(\"Current Time = \",start)\n",
    "\n",
    "final_features_train_w2v.drop(final_features_train_w2v.index[0], inplace=True)\n",
    "y_true_train = final_features_train_w2v['is_duplicate']\n",
    "final_features_train_w2v.drop(['Unnamed: 0', 'id','is_duplicate'], axis=1, inplace=True)\n",
    "\n",
    "final_features_test_w2v.drop(final_features_test_w2v.index[0], inplace=True)\n",
    "y_true_test = final_features_test_w2v['is_duplicate']\n",
    "final_features_test_w2v.drop(['Unnamed: 0', 'id','is_duplicate'], axis=1, inplace=True)\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Time taken to run this cell: \",current_time-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>...</th>\n",
       "      <th>374_y</th>\n",
       "      <th>375_y</th>\n",
       "      <th>376_y</th>\n",
       "      <th>377_y</th>\n",
       "      <th>378_y</th>\n",
       "      <th>379_y</th>\n",
       "      <th>380_y</th>\n",
       "      <th>381_y</th>\n",
       "      <th>382_y</th>\n",
       "      <th>383_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.734211</td>\n",
       "      <td>27.826567</td>\n",
       "      <td>13.032731</td>\n",
       "      <td>-6.930430</td>\n",
       "      <td>3.324043</td>\n",
       "      <td>0.948788</td>\n",
       "      <td>-23.472008</td>\n",
       "      <td>3.298593</td>\n",
       "      <td>28.678169</td>\n",
       "      <td>9.660554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.384814</td>\n",
       "      <td>3.862209</td>\n",
       "      <td>16.417156</td>\n",
       "      <td>-3.425271</td>\n",
       "      <td>-12.746041</td>\n",
       "      <td>-3.043191</td>\n",
       "      <td>-4.743920</td>\n",
       "      <td>12.397037</td>\n",
       "      <td>-0.398171</td>\n",
       "      <td>-13.135662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.311258</td>\n",
       "      <td>12.988016</td>\n",
       "      <td>0.664790</td>\n",
       "      <td>-4.728610</td>\n",
       "      <td>10.399462</td>\n",
       "      <td>5.935001</td>\n",
       "      <td>-4.696811</td>\n",
       "      <td>2.790680</td>\n",
       "      <td>20.241084</td>\n",
       "      <td>-5.227907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.638970</td>\n",
       "      <td>-1.372965</td>\n",
       "      <td>-0.314083</td>\n",
       "      <td>-22.204033</td>\n",
       "      <td>5.011401</td>\n",
       "      <td>15.180408</td>\n",
       "      <td>-10.172982</td>\n",
       "      <td>15.786889</td>\n",
       "      <td>2.275847</td>\n",
       "      <td>2.753095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.888879</td>\n",
       "      <td>0.799992</td>\n",
       "      <td>0.705878</td>\n",
       "      <td>0.705878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.850638</td>\n",
       "      <td>2.975380</td>\n",
       "      <td>9.910241</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>-5.671324</td>\n",
       "      <td>9.163055</td>\n",
       "      <td>-7.469239</td>\n",
       "      <td>4.996450</td>\n",
       "      <td>8.493940</td>\n",
       "      <td>2.154523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "1  0.799984  0.399996  0.749981  0.599988  0.699993  0.466664           0.0   \n",
       "2  0.399992  0.333328  0.399992  0.249997  0.399996  0.285712           0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000           0.0   \n",
       "4  0.399992  0.199998  0.999950  0.666644  0.571420  0.307690           0.0   \n",
       "5  0.666656  0.571420  0.888879  0.799992  0.705878  0.705878           1.0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len    ...          374_y      375_y  \\\n",
       "1            1.0           5.0      12.5    ...       8.734211  27.826567   \n",
       "2            1.0           4.0      12.0    ...     -18.384814   3.862209   \n",
       "3            0.0           2.0      12.0    ...      10.311258  12.988016   \n",
       "4            1.0           6.0      10.0    ...      16.638970  -1.372965   \n",
       "5            0.0           0.0      17.0    ...       7.850638   2.975380   \n",
       "\n",
       "       376_y      377_y      378_y      379_y      380_y      381_y  \\\n",
       "1  13.032731  -6.930430   3.324043   0.948788 -23.472008   3.298593   \n",
       "2  16.417156  -3.425271 -12.746041  -3.043191  -4.743920  12.397037   \n",
       "3   0.664790  -4.728610  10.399462   5.935001  -4.696811   2.790680   \n",
       "4  -0.314083 -22.204033   5.011401  15.180408 -10.172982  15.786889   \n",
       "5   9.910241   0.588800  -5.671324   9.163055  -7.469239   4.996450   \n",
       "\n",
       "       382_y      383_y  \n",
       "1  28.678169   9.660554  \n",
       "2  -0.398171 -13.135662  \n",
       "3  20.241084  -5.227907  \n",
       "4   2.275847   2.753095  \n",
       "5   8.493940   2.154523  \n",
       "\n",
       "[5 rows x 794 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_train_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>...</th>\n",
       "      <th>374_y</th>\n",
       "      <th>375_y</th>\n",
       "      <th>376_y</th>\n",
       "      <th>377_y</th>\n",
       "      <th>378_y</th>\n",
       "      <th>379_y</th>\n",
       "      <th>380_y</th>\n",
       "      <th>381_y</th>\n",
       "      <th>382_y</th>\n",
       "      <th>383_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.133332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "1  0.399992  0.249997  0.000000  0.000000  0.153845  0.133332           0.0   \n",
       "2  0.666644  0.499988  0.666644  0.499988  0.571420  0.571420           0.0   \n",
       "3  0.999967  0.749981  0.999975  0.799984  0.999986  0.777769           0.0   \n",
       "4  0.249997  0.249997  0.142855  0.083333  0.187499  0.124999           0.0   \n",
       "5  0.499988  0.499988  0.499975  0.199996  0.499992  0.333330           0.0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  ...    374_y  375_y  376_y  377_y  \\\n",
       "1            0.0           2.0      14.0  ...      NaN    NaN    NaN    NaN   \n",
       "2            0.0           0.0       7.0  ...      NaN    NaN    NaN    NaN   \n",
       "3            1.0           2.0       8.0  ...      NaN    NaN    NaN    NaN   \n",
       "4            0.0           8.0      20.0  ...      NaN    NaN    NaN    NaN   \n",
       "5            0.0           3.0       7.5  ...      NaN    NaN    NaN    NaN   \n",
       "\n",
       "   378_y  379_y  380_y  381_y  382_y  383_y  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "5    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 794 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_test_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "def reset_index(data_frame):\n",
    "    data_frame = data_frame.reset_index()\n",
    "    data_frame['index_col'] = data_frame.index\n",
    "\n",
    "    data_frame = data_frame.drop(\"index\", axis=1)\n",
    "    data_frame = data_frame.drop(\"index_col\", axis=1)\n",
    "    return(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_train_w2v = reset_index(final_features_train_w2v)\n",
    "final_features_test_w2v = reset_index(final_features_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7368789/convert-all-strings-in-a-list-to-int\n",
    "y_true_train = list(map(int, y_true_train.values))\n",
    "y_true_test = list(map(int, y_true_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999,)\n",
      "(29999,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_true_train))\n",
    "print(np.shape(y_true_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Converting strings to numerics </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 18:01:52.631847\n",
      "cwc_min\n",
      "cwc_max\n",
      "csc_min\n",
      "csc_max\n",
      "ctc_min\n",
      "ctc_max\n",
      "last_word_eq\n",
      "first_word_eq\n",
      "abs_len_diff\n",
      "mean_len\n",
      "token_set_ratio\n",
      "token_sort_ratio\n",
      "fuzz_ratio\n",
      "fuzz_partial_ratio\n",
      "longest_substr_ratio\n",
      "freq_qid1\n",
      "freq_qid2\n",
      "q1len\n",
      "q2len\n",
      "q1_n_words\n",
      "q2_n_words\n",
      "word_Common\n",
      "word_Total\n",
      "word_share\n",
      "freq_q1+q2\n",
      "freq_q1-q2\n",
      "0_x\n",
      "1_x\n",
      "2_x\n",
      "3_x\n",
      "4_x\n",
      "5_x\n",
      "6_x\n",
      "7_x\n",
      "8_x\n",
      "9_x\n",
      "10_x\n",
      "11_x\n",
      "12_x\n",
      "13_x\n",
      "14_x\n",
      "15_x\n",
      "16_x\n",
      "17_x\n",
      "18_x\n",
      "19_x\n",
      "20_x\n",
      "21_x\n",
      "22_x\n",
      "23_x\n",
      "24_x\n",
      "25_x\n",
      "26_x\n",
      "27_x\n",
      "28_x\n",
      "29_x\n",
      "30_x\n",
      "31_x\n",
      "32_x\n",
      "33_x\n",
      "34_x\n",
      "35_x\n",
      "36_x\n",
      "37_x\n",
      "38_x\n",
      "39_x\n",
      "40_x\n",
      "41_x\n",
      "42_x\n",
      "43_x\n",
      "44_x\n",
      "45_x\n",
      "46_x\n",
      "47_x\n",
      "48_x\n",
      "49_x\n",
      "50_x\n",
      "51_x\n",
      "52_x\n",
      "53_x\n",
      "54_x\n",
      "55_x\n",
      "56_x\n",
      "57_x\n",
      "58_x\n",
      "59_x\n",
      "60_x\n",
      "61_x\n",
      "62_x\n",
      "63_x\n",
      "64_x\n",
      "65_x\n",
      "66_x\n",
      "67_x\n",
      "68_x\n",
      "69_x\n",
      "70_x\n",
      "71_x\n",
      "72_x\n",
      "73_x\n",
      "74_x\n",
      "75_x\n",
      "76_x\n",
      "77_x\n",
      "78_x\n",
      "79_x\n",
      "80_x\n",
      "81_x\n",
      "82_x\n",
      "83_x\n",
      "84_x\n",
      "85_x\n",
      "86_x\n",
      "87_x\n",
      "88_x\n",
      "89_x\n",
      "90_x\n",
      "91_x\n",
      "92_x\n",
      "93_x\n",
      "94_x\n",
      "95_x\n",
      "96_x\n",
      "97_x\n",
      "98_x\n",
      "99_x\n",
      "100_x\n",
      "101_x\n",
      "102_x\n",
      "103_x\n",
      "104_x\n",
      "105_x\n",
      "106_x\n",
      "107_x\n",
      "108_x\n",
      "109_x\n",
      "110_x\n",
      "111_x\n",
      "112_x\n",
      "113_x\n",
      "114_x\n",
      "115_x\n",
      "116_x\n",
      "117_x\n",
      "118_x\n",
      "119_x\n",
      "120_x\n",
      "121_x\n",
      "122_x\n",
      "123_x\n",
      "124_x\n",
      "125_x\n",
      "126_x\n",
      "127_x\n",
      "128_x\n",
      "129_x\n",
      "130_x\n",
      "131_x\n",
      "132_x\n",
      "133_x\n",
      "134_x\n",
      "135_x\n",
      "136_x\n",
      "137_x\n",
      "138_x\n",
      "139_x\n",
      "140_x\n",
      "141_x\n",
      "142_x\n",
      "143_x\n",
      "144_x\n",
      "145_x\n",
      "146_x\n",
      "147_x\n",
      "148_x\n",
      "149_x\n",
      "150_x\n",
      "151_x\n",
      "152_x\n",
      "153_x\n",
      "154_x\n",
      "155_x\n",
      "156_x\n",
      "157_x\n",
      "158_x\n",
      "159_x\n",
      "160_x\n",
      "161_x\n",
      "162_x\n",
      "163_x\n",
      "164_x\n",
      "165_x\n",
      "166_x\n",
      "167_x\n",
      "168_x\n",
      "169_x\n",
      "170_x\n",
      "171_x\n",
      "172_x\n",
      "173_x\n",
      "174_x\n",
      "175_x\n",
      "176_x\n",
      "177_x\n",
      "178_x\n",
      "179_x\n",
      "180_x\n",
      "181_x\n",
      "182_x\n",
      "183_x\n",
      "184_x\n",
      "185_x\n",
      "186_x\n",
      "187_x\n",
      "188_x\n",
      "189_x\n",
      "190_x\n",
      "191_x\n",
      "192_x\n",
      "193_x\n",
      "194_x\n",
      "195_x\n",
      "196_x\n",
      "197_x\n",
      "198_x\n",
      "199_x\n",
      "200_x\n",
      "201_x\n",
      "202_x\n",
      "203_x\n",
      "204_x\n",
      "205_x\n",
      "206_x\n",
      "207_x\n",
      "208_x\n",
      "209_x\n",
      "210_x\n",
      "211_x\n",
      "212_x\n",
      "213_x\n",
      "214_x\n",
      "215_x\n",
      "216_x\n",
      "217_x\n",
      "218_x\n",
      "219_x\n",
      "220_x\n",
      "221_x\n",
      "222_x\n",
      "223_x\n",
      "224_x\n",
      "225_x\n",
      "226_x\n",
      "227_x\n",
      "228_x\n",
      "229_x\n",
      "230_x\n",
      "231_x\n",
      "232_x\n",
      "233_x\n",
      "234_x\n",
      "235_x\n",
      "236_x\n",
      "237_x\n",
      "238_x\n",
      "239_x\n",
      "240_x\n",
      "241_x\n",
      "242_x\n",
      "243_x\n",
      "244_x\n",
      "245_x\n",
      "246_x\n",
      "247_x\n",
      "248_x\n",
      "249_x\n",
      "250_x\n",
      "251_x\n",
      "252_x\n",
      "253_x\n",
      "254_x\n",
      "255_x\n",
      "256_x\n",
      "257_x\n",
      "258_x\n",
      "259_x\n",
      "260_x\n",
      "261_x\n",
      "262_x\n",
      "263_x\n",
      "264_x\n",
      "265_x\n",
      "266_x\n",
      "267_x\n",
      "268_x\n",
      "269_x\n",
      "270_x\n",
      "271_x\n",
      "272_x\n",
      "273_x\n",
      "274_x\n",
      "275_x\n",
      "276_x\n",
      "277_x\n",
      "278_x\n",
      "279_x\n",
      "280_x\n",
      "281_x\n",
      "282_x\n",
      "283_x\n",
      "284_x\n",
      "285_x\n",
      "286_x\n",
      "287_x\n",
      "288_x\n",
      "289_x\n",
      "290_x\n",
      "291_x\n",
      "292_x\n",
      "293_x\n",
      "294_x\n",
      "295_x\n",
      "296_x\n",
      "297_x\n",
      "298_x\n",
      "299_x\n",
      "300_x\n",
      "301_x\n",
      "302_x\n",
      "303_x\n",
      "304_x\n",
      "305_x\n",
      "306_x\n",
      "307_x\n",
      "308_x\n",
      "309_x\n",
      "310_x\n",
      "311_x\n",
      "312_x\n",
      "313_x\n",
      "314_x\n",
      "315_x\n",
      "316_x\n",
      "317_x\n",
      "318_x\n",
      "319_x\n",
      "320_x\n",
      "321_x\n",
      "322_x\n",
      "323_x\n",
      "324_x\n",
      "325_x\n",
      "326_x\n",
      "327_x\n",
      "328_x\n",
      "329_x\n",
      "330_x\n",
      "331_x\n",
      "332_x\n",
      "333_x\n",
      "334_x\n",
      "335_x\n",
      "336_x\n",
      "337_x\n",
      "338_x\n",
      "339_x\n",
      "340_x\n",
      "341_x\n",
      "342_x\n",
      "343_x\n",
      "344_x\n",
      "345_x\n",
      "346_x\n",
      "347_x\n",
      "348_x\n",
      "349_x\n",
      "350_x\n",
      "351_x\n",
      "352_x\n",
      "353_x\n",
      "354_x\n",
      "355_x\n",
      "356_x\n",
      "357_x\n",
      "358_x\n",
      "359_x\n",
      "360_x\n",
      "361_x\n",
      "362_x\n",
      "363_x\n",
      "364_x\n",
      "365_x\n",
      "366_x\n",
      "367_x\n",
      "368_x\n",
      "369_x\n",
      "370_x\n",
      "371_x\n",
      "372_x\n",
      "373_x\n",
      "374_x\n",
      "375_x\n",
      "376_x\n",
      "377_x\n",
      "378_x\n",
      "379_x\n",
      "380_x\n",
      "381_x\n",
      "382_x\n",
      "383_x\n",
      "0_y\n",
      "1_y\n",
      "2_y\n",
      "3_y\n",
      "4_y\n",
      "5_y\n",
      "6_y\n",
      "7_y\n",
      "8_y\n",
      "9_y\n",
      "10_y\n",
      "11_y\n",
      "12_y\n",
      "13_y\n",
      "14_y\n",
      "15_y\n",
      "16_y\n",
      "17_y\n",
      "18_y\n",
      "19_y\n",
      "20_y\n",
      "21_y\n",
      "22_y\n",
      "23_y\n",
      "24_y\n",
      "25_y\n",
      "26_y\n",
      "27_y\n",
      "28_y\n",
      "29_y\n",
      "30_y\n",
      "31_y\n",
      "32_y\n",
      "33_y\n",
      "34_y\n",
      "35_y\n",
      "36_y\n",
      "37_y\n",
      "38_y\n",
      "39_y\n",
      "40_y\n",
      "41_y\n",
      "42_y\n",
      "43_y\n",
      "44_y\n",
      "45_y\n",
      "46_y\n",
      "47_y\n",
      "48_y\n",
      "49_y\n",
      "50_y\n",
      "51_y\n",
      "52_y\n",
      "53_y\n",
      "54_y\n",
      "55_y\n",
      "56_y\n",
      "57_y\n",
      "58_y\n",
      "59_y\n",
      "60_y\n",
      "61_y\n",
      "62_y\n",
      "63_y\n",
      "64_y\n",
      "65_y\n",
      "66_y\n",
      "67_y\n",
      "68_y\n",
      "69_y\n",
      "70_y\n",
      "71_y\n",
      "72_y\n",
      "73_y\n",
      "74_y\n",
      "75_y\n",
      "76_y\n",
      "77_y\n",
      "78_y\n",
      "79_y\n",
      "80_y\n",
      "81_y\n",
      "82_y\n",
      "83_y\n",
      "84_y\n",
      "85_y\n",
      "86_y\n",
      "87_y\n",
      "88_y\n",
      "89_y\n",
      "90_y\n",
      "91_y\n",
      "92_y\n",
      "93_y\n",
      "94_y\n",
      "95_y\n",
      "96_y\n",
      "97_y\n",
      "98_y\n",
      "99_y\n",
      "100_y\n",
      "101_y\n",
      "102_y\n",
      "103_y\n",
      "104_y\n",
      "105_y\n",
      "106_y\n",
      "107_y\n",
      "108_y\n",
      "109_y\n",
      "110_y\n",
      "111_y\n",
      "112_y\n",
      "113_y\n",
      "114_y\n",
      "115_y\n",
      "116_y\n",
      "117_y\n",
      "118_y\n",
      "119_y\n",
      "120_y\n",
      "121_y\n",
      "122_y\n",
      "123_y\n",
      "124_y\n",
      "125_y\n",
      "126_y\n",
      "127_y\n",
      "128_y\n",
      "129_y\n",
      "130_y\n",
      "131_y\n",
      "132_y\n",
      "133_y\n",
      "134_y\n",
      "135_y\n",
      "136_y\n",
      "137_y\n",
      "138_y\n",
      "139_y\n",
      "140_y\n",
      "141_y\n",
      "142_y\n",
      "143_y\n",
      "144_y\n",
      "145_y\n",
      "146_y\n",
      "147_y\n",
      "148_y\n",
      "149_y\n",
      "150_y\n",
      "151_y\n",
      "152_y\n",
      "153_y\n",
      "154_y\n",
      "155_y\n",
      "156_y\n",
      "157_y\n",
      "158_y\n",
      "159_y\n",
      "160_y\n",
      "161_y\n",
      "162_y\n",
      "163_y\n",
      "164_y\n",
      "165_y\n",
      "166_y\n",
      "167_y\n",
      "168_y\n",
      "169_y\n",
      "170_y\n",
      "171_y\n",
      "172_y\n",
      "173_y\n",
      "174_y\n",
      "175_y\n",
      "176_y\n",
      "177_y\n",
      "178_y\n",
      "179_y\n",
      "180_y\n",
      "181_y\n",
      "182_y\n",
      "183_y\n",
      "184_y\n",
      "185_y\n",
      "186_y\n",
      "187_y\n",
      "188_y\n",
      "189_y\n",
      "190_y\n",
      "191_y\n",
      "192_y\n",
      "193_y\n",
      "194_y\n",
      "195_y\n",
      "196_y\n",
      "197_y\n",
      "198_y\n",
      "199_y\n",
      "200_y\n",
      "201_y\n",
      "202_y\n",
      "203_y\n",
      "204_y\n",
      "205_y\n",
      "206_y\n",
      "207_y\n",
      "208_y\n",
      "209_y\n",
      "210_y\n",
      "211_y\n",
      "212_y\n",
      "213_y\n",
      "214_y\n",
      "215_y\n",
      "216_y\n",
      "217_y\n",
      "218_y\n",
      "219_y\n",
      "220_y\n",
      "221_y\n",
      "222_y\n",
      "223_y\n",
      "224_y\n",
      "225_y\n",
      "226_y\n",
      "227_y\n",
      "228_y\n",
      "229_y\n",
      "230_y\n",
      "231_y\n",
      "232_y\n",
      "233_y\n",
      "234_y\n",
      "235_y\n",
      "236_y\n",
      "237_y\n",
      "238_y\n",
      "239_y\n",
      "240_y\n",
      "241_y\n",
      "242_y\n",
      "243_y\n",
      "244_y\n",
      "245_y\n",
      "246_y\n",
      "247_y\n",
      "248_y\n",
      "249_y\n",
      "250_y\n",
      "251_y\n",
      "252_y\n",
      "253_y\n",
      "254_y\n",
      "255_y\n",
      "256_y\n",
      "257_y\n",
      "258_y\n",
      "259_y\n",
      "260_y\n",
      "261_y\n",
      "262_y\n",
      "263_y\n",
      "264_y\n",
      "265_y\n",
      "266_y\n",
      "267_y\n",
      "268_y\n",
      "269_y\n",
      "270_y\n",
      "271_y\n",
      "272_y\n",
      "273_y\n",
      "274_y\n",
      "275_y\n",
      "276_y\n",
      "277_y\n",
      "278_y\n",
      "279_y\n",
      "280_y\n",
      "281_y\n",
      "282_y\n",
      "283_y\n",
      "284_y\n",
      "285_y\n",
      "286_y\n",
      "287_y\n",
      "288_y\n",
      "289_y\n",
      "290_y\n",
      "291_y\n",
      "292_y\n",
      "293_y\n",
      "294_y\n",
      "295_y\n",
      "296_y\n",
      "297_y\n",
      "298_y\n",
      "299_y\n",
      "300_y\n",
      "301_y\n",
      "302_y\n",
      "303_y\n",
      "304_y\n",
      "305_y\n",
      "306_y\n",
      "307_y\n",
      "308_y\n",
      "309_y\n",
      "310_y\n",
      "311_y\n",
      "312_y\n",
      "313_y\n",
      "314_y\n",
      "315_y\n",
      "316_y\n",
      "317_y\n",
      "318_y\n",
      "319_y\n",
      "320_y\n",
      "321_y\n",
      "322_y\n",
      "323_y\n",
      "324_y\n",
      "325_y\n",
      "326_y\n",
      "327_y\n",
      "328_y\n",
      "329_y\n",
      "330_y\n",
      "331_y\n",
      "332_y\n",
      "333_y\n",
      "334_y\n",
      "335_y\n",
      "336_y\n",
      "337_y\n",
      "338_y\n",
      "339_y\n",
      "340_y\n",
      "341_y\n",
      "342_y\n",
      "343_y\n",
      "344_y\n",
      "345_y\n",
      "346_y\n",
      "347_y\n",
      "348_y\n",
      "349_y\n",
      "350_y\n",
      "351_y\n",
      "352_y\n",
      "353_y\n",
      "354_y\n",
      "355_y\n",
      "356_y\n",
      "357_y\n",
      "358_y\n",
      "359_y\n",
      "360_y\n",
      "361_y\n",
      "362_y\n",
      "363_y\n",
      "364_y\n",
      "365_y\n",
      "366_y\n",
      "367_y\n",
      "368_y\n",
      "369_y\n",
      "370_y\n",
      "371_y\n",
      "372_y\n",
      "373_y\n",
      "374_y\n",
      "375_y\n",
      "376_y\n",
      "377_y\n",
      "378_y\n",
      "379_y\n",
      "380_y\n",
      "381_y\n",
      "382_y\n",
      "383_y\n",
      "Time taken to run this cell:  0:15:25.797741\n",
      "Current Time =  2019-05-16 18:17:18.437590\n",
      "cwc_min\n",
      "cwc_max\n",
      "csc_min\n",
      "csc_max\n",
      "ctc_min\n",
      "ctc_max\n",
      "last_word_eq\n",
      "first_word_eq\n",
      "abs_len_diff\n",
      "mean_len\n",
      "token_set_ratio\n",
      "token_sort_ratio\n",
      "fuzz_ratio\n",
      "fuzz_partial_ratio\n",
      "longest_substr_ratio\n",
      "freq_qid1\n",
      "freq_qid2\n",
      "q1len\n",
      "q2len\n",
      "q1_n_words\n",
      "q2_n_words\n",
      "word_Common\n",
      "word_Total\n",
      "word_share\n",
      "freq_q1+q2\n",
      "freq_q1-q2\n",
      "0_x\n",
      "1_x\n",
      "2_x\n",
      "3_x\n",
      "4_x\n",
      "5_x\n",
      "6_x\n",
      "7_x\n",
      "8_x\n",
      "9_x\n",
      "10_x\n",
      "11_x\n",
      "12_x\n",
      "13_x\n",
      "14_x\n",
      "15_x\n",
      "16_x\n",
      "17_x\n",
      "18_x\n",
      "19_x\n",
      "20_x\n",
      "21_x\n",
      "22_x\n",
      "23_x\n",
      "24_x\n",
      "25_x\n",
      "26_x\n",
      "27_x\n",
      "28_x\n",
      "29_x\n",
      "30_x\n",
      "31_x\n",
      "32_x\n",
      "33_x\n",
      "34_x\n",
      "35_x\n",
      "36_x\n",
      "37_x\n",
      "38_x\n",
      "39_x\n",
      "40_x\n",
      "41_x\n",
      "42_x\n",
      "43_x\n",
      "44_x\n",
      "45_x\n",
      "46_x\n",
      "47_x\n",
      "48_x\n",
      "49_x\n",
      "50_x\n",
      "51_x\n",
      "52_x\n",
      "53_x\n",
      "54_x\n",
      "55_x\n",
      "56_x\n",
      "57_x\n",
      "58_x\n",
      "59_x\n",
      "60_x\n",
      "61_x\n",
      "62_x\n",
      "63_x\n",
      "64_x\n",
      "65_x\n",
      "66_x\n",
      "67_x\n",
      "68_x\n",
      "69_x\n",
      "70_x\n",
      "71_x\n",
      "72_x\n",
      "73_x\n",
      "74_x\n",
      "75_x\n",
      "76_x\n",
      "77_x\n",
      "78_x\n",
      "79_x\n",
      "80_x\n",
      "81_x\n",
      "82_x\n",
      "83_x\n",
      "84_x\n",
      "85_x\n",
      "86_x\n",
      "87_x\n",
      "88_x\n",
      "89_x\n",
      "90_x\n",
      "91_x\n",
      "92_x\n",
      "93_x\n",
      "94_x\n",
      "95_x\n",
      "96_x\n",
      "97_x\n",
      "98_x\n",
      "99_x\n",
      "100_x\n",
      "101_x\n",
      "102_x\n",
      "103_x\n",
      "104_x\n",
      "105_x\n",
      "106_x\n",
      "107_x\n",
      "108_x\n",
      "109_x\n",
      "110_x\n",
      "111_x\n",
      "112_x\n",
      "113_x\n",
      "114_x\n",
      "115_x\n",
      "116_x\n",
      "117_x\n",
      "118_x\n",
      "119_x\n",
      "120_x\n",
      "121_x\n",
      "122_x\n",
      "123_x\n",
      "124_x\n",
      "125_x\n",
      "126_x\n",
      "127_x\n",
      "128_x\n",
      "129_x\n",
      "130_x\n",
      "131_x\n",
      "132_x\n",
      "133_x\n",
      "134_x\n",
      "135_x\n",
      "136_x\n",
      "137_x\n",
      "138_x\n",
      "139_x\n",
      "140_x\n",
      "141_x\n",
      "142_x\n",
      "143_x\n",
      "144_x\n",
      "145_x\n",
      "146_x\n",
      "147_x\n",
      "148_x\n",
      "149_x\n",
      "150_x\n",
      "151_x\n",
      "152_x\n",
      "153_x\n",
      "154_x\n",
      "155_x\n",
      "156_x\n",
      "157_x\n",
      "158_x\n",
      "159_x\n",
      "160_x\n",
      "161_x\n",
      "162_x\n",
      "163_x\n",
      "164_x\n",
      "165_x\n",
      "166_x\n",
      "167_x\n",
      "168_x\n",
      "169_x\n",
      "170_x\n",
      "171_x\n",
      "172_x\n",
      "173_x\n",
      "174_x\n",
      "175_x\n",
      "176_x\n",
      "177_x\n",
      "178_x\n",
      "179_x\n",
      "180_x\n",
      "181_x\n",
      "182_x\n",
      "183_x\n",
      "184_x\n",
      "185_x\n",
      "186_x\n",
      "187_x\n",
      "188_x\n",
      "189_x\n",
      "190_x\n",
      "191_x\n",
      "192_x\n",
      "193_x\n",
      "194_x\n",
      "195_x\n",
      "196_x\n",
      "197_x\n",
      "198_x\n",
      "199_x\n",
      "200_x\n",
      "201_x\n",
      "202_x\n",
      "203_x\n",
      "204_x\n",
      "205_x\n",
      "206_x\n",
      "207_x\n",
      "208_x\n",
      "209_x\n",
      "210_x\n",
      "211_x\n",
      "212_x\n",
      "213_x\n",
      "214_x\n",
      "215_x\n",
      "216_x\n",
      "217_x\n",
      "218_x\n",
      "219_x\n",
      "220_x\n",
      "221_x\n",
      "222_x\n",
      "223_x\n",
      "224_x\n",
      "225_x\n",
      "226_x\n",
      "227_x\n",
      "228_x\n",
      "229_x\n",
      "230_x\n",
      "231_x\n",
      "232_x\n",
      "233_x\n",
      "234_x\n",
      "235_x\n",
      "236_x\n",
      "237_x\n",
      "238_x\n",
      "239_x\n",
      "240_x\n",
      "241_x\n",
      "242_x\n",
      "243_x\n",
      "244_x\n",
      "245_x\n",
      "246_x\n",
      "247_x\n",
      "248_x\n",
      "249_x\n",
      "250_x\n",
      "251_x\n",
      "252_x\n",
      "253_x\n",
      "254_x\n",
      "255_x\n",
      "256_x\n",
      "257_x\n",
      "258_x\n",
      "259_x\n",
      "260_x\n",
      "261_x\n",
      "262_x\n",
      "263_x\n",
      "264_x\n",
      "265_x\n",
      "266_x\n",
      "267_x\n",
      "268_x\n",
      "269_x\n",
      "270_x\n",
      "271_x\n",
      "272_x\n",
      "273_x\n",
      "274_x\n",
      "275_x\n",
      "276_x\n",
      "277_x\n",
      "278_x\n",
      "279_x\n",
      "280_x\n",
      "281_x\n",
      "282_x\n",
      "283_x\n",
      "284_x\n",
      "285_x\n",
      "286_x\n",
      "287_x\n",
      "288_x\n",
      "289_x\n",
      "290_x\n",
      "291_x\n",
      "292_x\n",
      "293_x\n",
      "294_x\n",
      "295_x\n",
      "296_x\n",
      "297_x\n",
      "298_x\n",
      "299_x\n",
      "300_x\n",
      "301_x\n",
      "302_x\n",
      "303_x\n",
      "304_x\n",
      "305_x\n",
      "306_x\n",
      "307_x\n",
      "308_x\n",
      "309_x\n",
      "310_x\n",
      "311_x\n",
      "312_x\n",
      "313_x\n",
      "314_x\n",
      "315_x\n",
      "316_x\n",
      "317_x\n",
      "318_x\n",
      "319_x\n",
      "320_x\n",
      "321_x\n",
      "322_x\n",
      "323_x\n",
      "324_x\n",
      "325_x\n",
      "326_x\n",
      "327_x\n",
      "328_x\n",
      "329_x\n",
      "330_x\n",
      "331_x\n",
      "332_x\n",
      "333_x\n",
      "334_x\n",
      "335_x\n",
      "336_x\n",
      "337_x\n",
      "338_x\n",
      "339_x\n",
      "340_x\n",
      "341_x\n",
      "342_x\n",
      "343_x\n",
      "344_x\n",
      "345_x\n",
      "346_x\n",
      "347_x\n",
      "348_x\n",
      "349_x\n",
      "350_x\n",
      "351_x\n",
      "352_x\n",
      "353_x\n",
      "354_x\n",
      "355_x\n",
      "356_x\n",
      "357_x\n",
      "358_x\n",
      "359_x\n",
      "360_x\n",
      "361_x\n",
      "362_x\n",
      "363_x\n",
      "364_x\n",
      "365_x\n",
      "366_x\n",
      "367_x\n",
      "368_x\n",
      "369_x\n",
      "370_x\n",
      "371_x\n",
      "372_x\n",
      "373_x\n",
      "374_x\n",
      "375_x\n",
      "376_x\n",
      "377_x\n",
      "378_x\n",
      "379_x\n",
      "380_x\n",
      "381_x\n",
      "382_x\n",
      "383_x\n",
      "0_y\n",
      "1_y\n",
      "2_y\n",
      "3_y\n",
      "4_y\n",
      "5_y\n",
      "6_y\n",
      "7_y\n",
      "8_y\n",
      "9_y\n",
      "10_y\n",
      "11_y\n",
      "12_y\n",
      "13_y\n",
      "14_y\n",
      "15_y\n",
      "16_y\n",
      "17_y\n",
      "18_y\n",
      "19_y\n",
      "20_y\n",
      "21_y\n",
      "22_y\n",
      "23_y\n",
      "24_y\n",
      "25_y\n",
      "26_y\n",
      "27_y\n",
      "28_y\n",
      "29_y\n",
      "30_y\n",
      "31_y\n",
      "32_y\n",
      "33_y\n",
      "34_y\n",
      "35_y\n",
      "36_y\n",
      "37_y\n",
      "38_y\n",
      "39_y\n",
      "40_y\n",
      "41_y\n",
      "42_y\n",
      "43_y\n",
      "44_y\n",
      "45_y\n",
      "46_y\n",
      "47_y\n",
      "48_y\n",
      "49_y\n",
      "50_y\n",
      "51_y\n",
      "52_y\n",
      "53_y\n",
      "54_y\n",
      "55_y\n",
      "56_y\n",
      "57_y\n",
      "58_y\n",
      "59_y\n",
      "60_y\n",
      "61_y\n",
      "62_y\n",
      "63_y\n",
      "64_y\n",
      "65_y\n",
      "66_y\n",
      "67_y\n",
      "68_y\n",
      "69_y\n",
      "70_y\n",
      "71_y\n",
      "72_y\n",
      "73_y\n",
      "74_y\n",
      "75_y\n",
      "76_y\n",
      "77_y\n",
      "78_y\n",
      "79_y\n",
      "80_y\n",
      "81_y\n",
      "82_y\n",
      "83_y\n",
      "84_y\n",
      "85_y\n",
      "86_y\n",
      "87_y\n",
      "88_y\n",
      "89_y\n",
      "90_y\n",
      "91_y\n",
      "92_y\n",
      "93_y\n",
      "94_y\n",
      "95_y\n",
      "96_y\n",
      "97_y\n",
      "98_y\n",
      "99_y\n",
      "100_y\n",
      "101_y\n",
      "102_y\n",
      "103_y\n",
      "104_y\n",
      "105_y\n",
      "106_y\n",
      "107_y\n",
      "108_y\n",
      "109_y\n",
      "110_y\n",
      "111_y\n",
      "112_y\n",
      "113_y\n",
      "114_y\n",
      "115_y\n",
      "116_y\n",
      "117_y\n",
      "118_y\n",
      "119_y\n",
      "120_y\n",
      "121_y\n",
      "122_y\n",
      "123_y\n",
      "124_y\n",
      "125_y\n",
      "126_y\n",
      "127_y\n",
      "128_y\n",
      "129_y\n",
      "130_y\n",
      "131_y\n",
      "132_y\n",
      "133_y\n",
      "134_y\n",
      "135_y\n",
      "136_y\n",
      "137_y\n",
      "138_y\n",
      "139_y\n",
      "140_y\n",
      "141_y\n",
      "142_y\n",
      "143_y\n",
      "144_y\n",
      "145_y\n",
      "146_y\n",
      "147_y\n",
      "148_y\n",
      "149_y\n",
      "150_y\n",
      "151_y\n",
      "152_y\n",
      "153_y\n",
      "154_y\n",
      "155_y\n",
      "156_y\n",
      "157_y\n",
      "158_y\n",
      "159_y\n",
      "160_y\n",
      "161_y\n",
      "162_y\n",
      "163_y\n",
      "164_y\n",
      "165_y\n",
      "166_y\n",
      "167_y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168_y\n",
      "169_y\n",
      "170_y\n",
      "171_y\n",
      "172_y\n",
      "173_y\n",
      "174_y\n",
      "175_y\n",
      "176_y\n",
      "177_y\n",
      "178_y\n",
      "179_y\n",
      "180_y\n",
      "181_y\n",
      "182_y\n",
      "183_y\n",
      "184_y\n",
      "185_y\n",
      "186_y\n",
      "187_y\n",
      "188_y\n",
      "189_y\n",
      "190_y\n",
      "191_y\n",
      "192_y\n",
      "193_y\n",
      "194_y\n",
      "195_y\n",
      "196_y\n",
      "197_y\n",
      "198_y\n",
      "199_y\n",
      "200_y\n",
      "201_y\n",
      "202_y\n",
      "203_y\n",
      "204_y\n",
      "205_y\n",
      "206_y\n",
      "207_y\n",
      "208_y\n",
      "209_y\n",
      "210_y\n",
      "211_y\n",
      "212_y\n",
      "213_y\n",
      "214_y\n",
      "215_y\n",
      "216_y\n",
      "217_y\n",
      "218_y\n",
      "219_y\n",
      "220_y\n",
      "221_y\n",
      "222_y\n",
      "223_y\n",
      "224_y\n",
      "225_y\n",
      "226_y\n",
      "227_y\n",
      "228_y\n",
      "229_y\n",
      "230_y\n",
      "231_y\n",
      "232_y\n",
      "233_y\n",
      "234_y\n",
      "235_y\n",
      "236_y\n",
      "237_y\n",
      "238_y\n",
      "239_y\n",
      "240_y\n",
      "241_y\n",
      "242_y\n",
      "243_y\n",
      "244_y\n",
      "245_y\n",
      "246_y\n",
      "247_y\n",
      "248_y\n",
      "249_y\n",
      "250_y\n",
      "251_y\n",
      "252_y\n",
      "253_y\n",
      "254_y\n",
      "255_y\n",
      "256_y\n",
      "257_y\n",
      "258_y\n",
      "259_y\n",
      "260_y\n",
      "261_y\n",
      "262_y\n",
      "263_y\n",
      "264_y\n",
      "265_y\n",
      "266_y\n",
      "267_y\n",
      "268_y\n",
      "269_y\n",
      "270_y\n",
      "271_y\n",
      "272_y\n",
      "273_y\n",
      "274_y\n",
      "275_y\n",
      "276_y\n",
      "277_y\n",
      "278_y\n",
      "279_y\n",
      "280_y\n",
      "281_y\n",
      "282_y\n",
      "283_y\n",
      "284_y\n",
      "285_y\n",
      "286_y\n",
      "287_y\n",
      "288_y\n",
      "289_y\n",
      "290_y\n",
      "291_y\n",
      "292_y\n",
      "293_y\n",
      "294_y\n",
      "295_y\n",
      "296_y\n",
      "297_y\n",
      "298_y\n",
      "299_y\n",
      "300_y\n",
      "301_y\n",
      "302_y\n",
      "303_y\n",
      "304_y\n",
      "305_y\n",
      "306_y\n",
      "307_y\n",
      "308_y\n",
      "309_y\n",
      "310_y\n",
      "311_y\n",
      "312_y\n",
      "313_y\n",
      "314_y\n",
      "315_y\n",
      "316_y\n",
      "317_y\n",
      "318_y\n",
      "319_y\n",
      "320_y\n",
      "321_y\n",
      "322_y\n",
      "323_y\n",
      "324_y\n",
      "325_y\n",
      "326_y\n",
      "327_y\n",
      "328_y\n",
      "329_y\n",
      "330_y\n",
      "331_y\n",
      "332_y\n",
      "333_y\n",
      "334_y\n",
      "335_y\n",
      "336_y\n",
      "337_y\n",
      "338_y\n",
      "339_y\n",
      "340_y\n",
      "341_y\n",
      "342_y\n",
      "343_y\n",
      "344_y\n",
      "345_y\n",
      "346_y\n",
      "347_y\n",
      "348_y\n",
      "349_y\n",
      "350_y\n",
      "351_y\n",
      "352_y\n",
      "353_y\n",
      "354_y\n",
      "355_y\n",
      "356_y\n",
      "357_y\n",
      "358_y\n",
      "359_y\n",
      "360_y\n",
      "361_y\n",
      "362_y\n",
      "363_y\n",
      "364_y\n",
      "365_y\n",
      "366_y\n",
      "367_y\n",
      "368_y\n",
      "369_y\n",
      "370_y\n",
      "371_y\n",
      "372_y\n",
      "373_y\n",
      "374_y\n",
      "375_y\n",
      "376_y\n",
      "377_y\n",
      "378_y\n",
      "379_y\n",
      "380_y\n",
      "381_y\n",
      "382_y\n",
      "383_y\n",
      "Time taken to run this cell:  0:06:59.012886\n"
     ]
    }
   ],
   "source": [
    "# after we read from sql table each entry was read it as a string\n",
    "# we convert all the features into numaric before we apply any model\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(\"Current Time = \",start)\n",
    "\n",
    "cols = list(final_features_train_w2v.columns)\n",
    "for i in cols:\n",
    "    final_features_train_w2v[i] = final_features_train_w2v[i].apply(pd.to_numeric)\n",
    "    print(i)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Time taken to run this cell: \",current_time-start)\n",
    "\n",
    "start2 = datetime.datetime.now()\n",
    "print(\"Current Time = \",start2)\n",
    "    \n",
    "cols = list(final_features_test_w2v.columns)\n",
    "for i in cols:\n",
    "    final_features_test_w2v[i] = final_features_test_w2v[i].apply(pd.to_numeric)\n",
    "    print(i)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Time taken to run this cell: \",current_time-start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (69999, 794)\n",
      "Number of data points in test data : (29999, 794)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['y_test_w2v.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v = final_features_train_w2v\n",
    "X_test_w2v = final_features_test_w2v\n",
    "\n",
    "y_train_w2v = y_true_train\n",
    "y_test_w2v = y_true_test\n",
    "\n",
    "print(\"Number of data points in train data :\",X_train_w2v.shape)\n",
    "print(\"Number of data points in test data :\",X_test_w2v.shape)\n",
    "\n",
    "import joblib                                       #  * DO NOT RUN *\n",
    "joblib.dump(X_train_w2v,\"X_train_w2v.pkl\")\n",
    "joblib.dump(X_test_w2v,\"X_test_w2v.pkl\")\n",
    "joblib.dump(y_train_w2v,\"y_train_w2v.pkl\")\n",
    "joblib.dump(y_test_w2v,\"y_test_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved Train data frame\n",
    "X_train_w2v = joblib.load(\"X_train_w2v.pkl\")\n",
    "X_test_w2v = joblib.load(\"X_test_w2v.pkl\")\n",
    "\n",
    "y_train_w2v = joblib.load(\"y_train_w2v.pkl\")\n",
    "y_test_w2v = joblib.load(\"y_test_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scal = StandardScaler(with_mean=False)\n",
    "std_scal.fit(X_train_w2v)\n",
    "X_train_w2v = std_scal.transform(X_train_w2v)\n",
    "X_test_w2v = std_scal.transform(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.6275375362505179 Class 1:  0.3724624637494821\n",
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.3727124237474582 Class 1:  0.3727124237474582\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "train_distr = Counter(y_train_w2v)\n",
    "train_len = len(y_train_w2v)\n",
    "print(\"Class 0: \",int(train_distr[0])/train_len,\"Class 1: \", int(train_distr[1])/train_len)\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "test_distr = Counter(y_test_w2v)\n",
    "test_len = len(y_test_w2v)\n",
    "print(\"Class 0: \",int(test_distr[1])/test_len, \"Class 1: \",int(test_distr[1])/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 794)\n",
      "(69999,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_w2v))\n",
    "print(np.shape(y_train_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for NaN values\n",
    "def NaN_values(data_frame):\n",
    "    bool_series = pd.isnull(data_frame) \n",
    "  \n",
    "    # displayind data only with team = NaN \n",
    "    print(\"Number of rows with NaN values = \",len(data_frame[bool_series]))\n",
    "    return (data_frame[bool_series][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values =  15360000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = NaN_values(X_train_w2v)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = np.nan_to_num(X_train_w2v)   #Not required if there are no Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = NaN_values(X_train_w2v)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values =  23039232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = NaN_values(X_test_w2v)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with NaN values =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_w2v = np.nan_to_num(X_test_w2v)\n",
    "x = NaN_values(X_test_w2v)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/doing-xgboost-hyper-parameter-tuning-the-smart-way-part-1-of-2-f6d255a45dde\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "# https://www.kaggle.com/phunter/xgboost-with-gridsearchcv\n",
    "\n",
    "def xgboost_fun(X_train,y_train,X_test,y_test):\n",
    "    startTime3 = datetime.datetime.now()\n",
    "    print(\"Current Time = \",startTime3)\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    params = {\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.10, 0.15],\n",
    "              'max_depth': [3, 4, 5]}\n",
    "\n",
    "    grid = GridSearchCV(estimator=xgb, param_grid=params, scoring=\"neg_log_loss\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print('\\n All results:')\n",
    "    print(grid.cv_results_)\n",
    "    print('\\n Best estimator:')\n",
    "    print(grid.best_estimator_)\n",
    "    print('\\n Best score:')\n",
    "    print(grid.best_score_)\n",
    "    print('\\n Best parameters:')\n",
    "    print(grid.best_params_)\n",
    "\n",
    "    best_learning_rate = grid.best_params_['learning_rate']\n",
    "    print(\"Best learning rate: \", best_learning_rate)\n",
    "\n",
    "    best_max_depth = grid.best_params_['max_depth']\n",
    "    print(\"Best learning rate: \", best_max_depth)\n",
    "\n",
    "    import xgboost as xgb\n",
    "    startTime = datetime.datetime.now()\n",
    "    print(\"Current Time = \",startTime)\n",
    "\n",
    "    params = {}\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['eta'] = best_learning_rate\n",
    "    params['max_depth'] = best_max_depth\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
    "\n",
    "    bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "    xgdmat = xgb.DMatrix(X_train,y_train)\n",
    "    predict_y = bst.predict(d_test)\n",
    "    print(\"The test log loss is:\",log_loss(y_test, predict_y))\n",
    "\n",
    "    predicted_y =np.array(predict_y>0.5,dtype=int)\n",
    "    print(\"Total number of data points :\", len(predicted_y))\n",
    "    plot_confusion_matrix(y_test, predicted_y)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    print(\"Time taken to run this cell: \",current_time-startTime3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time =  2019-05-16 18:31:33.968261\n",
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([ 653.5812544 ,  861.12251989, 1154.35703754,  663.28987114,\n",
      "        914.61429874, 1106.59102098,  749.56274605,  871.73904928,\n",
      "       1092.72773496]), 'std_fit_time': array([ 62.72364266,  92.04326447, 171.1604059 ,  80.17650791,\n",
      "        74.52389569, 124.38047717,  55.80765727,  83.24759754,\n",
      "       119.05016455]), 'mean_score_time': array([0.9558332 , 0.94145799, 1.30407548, 0.98465149, 1.00734011,\n",
      "       1.09315872, 1.03318588, 0.96023448, 1.06322193]), 'std_score_time': array([0.05760403, 0.01177241, 0.3731702 , 0.04828628, 0.05771717,\n",
      "       0.06562035, 0.04512661, 0.00640076, 0.01864836]), 'param_learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_objective': masked_array(data=['binary:logistic', 'binary:logistic',\n",
      "                   'binary:logistic', 'binary:logistic',\n",
      "                   'binary:logistic', 'binary:logistic',\n",
      "                   'binary:logistic', 'binary:logistic',\n",
      "                   'binary:logistic'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.05, 'max_depth': 3, 'objective': 'binary:logistic'}, {'learning_rate': 0.05, 'max_depth': 4, 'objective': 'binary:logistic'}, {'learning_rate': 0.05, 'max_depth': 5, 'objective': 'binary:logistic'}, {'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic'}, {'learning_rate': 0.1, 'max_depth': 4, 'objective': 'binary:logistic'}, {'learning_rate': 0.1, 'max_depth': 5, 'objective': 'binary:logistic'}, {'learning_rate': 0.15, 'max_depth': 3, 'objective': 'binary:logistic'}, {'learning_rate': 0.15, 'max_depth': 4, 'objective': 'binary:logistic'}, {'learning_rate': 0.15, 'max_depth': 5, 'objective': 'binary:logistic'}], 'split0_test_score': array([-0.38497511, -0.37189755, -0.36160836, -0.36535962, -0.35556714,\n",
      "       -0.34895377, -0.35767269, -0.3499264 , -0.34636554]), 'split1_test_score': array([-0.38125343, -0.36805157, -0.35857873, -0.3620252 , -0.35124252,\n",
      "       -0.34547358, -0.3524951 , -0.34645493, -0.34186632]), 'split2_test_score': array([-0.38285192, -0.37052599, -0.36086673, -0.36268912, -0.35262111,\n",
      "       -0.3457925 , -0.35412685, -0.34732167, -0.34303273]), 'mean_test_score': array([-0.38302685, -0.37015839, -0.36035128, -0.36335802, -0.35314363,\n",
      "       -0.34674   , -0.35476493, -0.34790104, -0.34375491]), 'std_test_score': array([0.00152441, 0.0015915 , 0.00128944, 0.00144111, 0.00180378,\n",
      "       0.00157083, 0.00216138, 0.00147525, 0.00190648]), 'rank_test_score': array([9, 8, 6, 7, 4, 2, 5, 3, 1]), 'split0_train_score': array([-0.3792982 , -0.3625268 , -0.34511564, -0.35371431, -0.33310061,\n",
      "       -0.30690189, -0.33932141, -0.31267709, -0.27874682]), 'split1_train_score': array([-0.38055864, -0.36290692, -0.34516821, -0.355332  , -0.3337256 ,\n",
      "       -0.30903592, -0.34028812, -0.31505119, -0.28252504]), 'split2_train_score': array([-0.37989691, -0.3636694 , -0.34674743, -0.35532209, -0.33508678,\n",
      "       -0.30802187, -0.34053784, -0.3155074 , -0.28055645]), 'mean_train_score': array([-0.37991792, -0.36303437, -0.34567709, -0.35478946, -0.333971  ,\n",
      "       -0.30798656, -0.34004913, -0.31441189, -0.28060944]), 'std_train_score': array([0.00051479, 0.00047509, 0.00075715, 0.00076026, 0.00082921,\n",
      "       0.00087157, 0.00052457, 0.00124075, 0.00154291])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.15, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\n",
      " Best score:\n",
      "-0.3437549094199659\n",
      "\n",
      " Best parameters:\n",
      "{'learning_rate': 0.15, 'max_depth': 5, 'objective': 'binary:logistic'}\n",
      "Best learning rate:  0.15\n",
      "Best learning rate:  5\n",
      "Current Time =  2019-05-17 01:43:57.369705\n",
      "[01:44:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[0]\ttrain-logloss:0.630994\tvalid-logloss:0.632322\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "[01:44:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:45:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:45:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:45:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:45:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:46:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:46:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:46:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:47:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[10]\ttrain-logloss:0.411937\tvalid-logloss:0.419418\n",
      "[01:47:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:47:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:47:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:48:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:48:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:49:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:49:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:49:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:49:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[20]\ttrain-logloss:0.368487\tvalid-logloss:0.386765\n",
      "[01:50:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:50:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:50:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:50:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:51:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:51:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:51:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:52:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:52:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[30]\ttrain-logloss:0.351841\tvalid-logloss:0.413183\n",
      "[01:52:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:53:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:53:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:53:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:53:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:54:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:54:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:54:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:55:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:55:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[40]\ttrain-logloss:0.340614\tvalid-logloss:0.407638\n",
      "[01:55:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:55:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:56:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:56:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:56:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[01:56:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-logloss:0.357027\tvalid-logloss:0.38383\n",
      "\n",
      "The test log loss is: 0.45605028405095477\n",
      "Total number of data points : 29999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell:  7:25:41.483273\n"
     ]
    }
   ],
   "source": [
    "xgboost_fun(X_train_w2v,y_train_w2v,X_test_w2v,y_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
